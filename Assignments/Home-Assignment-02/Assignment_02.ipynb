{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Average Word Count"
      ],
      "metadata": {
        "id": "dChOpk8VSXsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile urdu-text.txt\n",
        "یہ ایک مثال ہے۔ یہ مثال الفاظ کی گنتی کے لیے ہے۔\n",
        "یہ الفاظ کو گننے کا ایک آسان طریقہ ہے۔"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biflkMb6SdAW",
        "outputId": "54533348-d69e-4fb2-de1d-dabeffbcfc82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing urdu-text.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Sample Urdu text\n",
        "file_path = \"urdu-text.txt\"\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    # Split the text into sentences using Urdu-specific punctuation\n",
        "    urdu_text = file.read()\n",
        "    # Remove non-word characters and extra whitespaces\n",
        "    text = re.sub(r'[^\\w\\s\\u0600-\\u06FF]', '', urdu_text)\n",
        "\n",
        "    sentences = text.split()\n",
        "    # Remove empty strings and trim sentences\n",
        "    sentences = [sentence.strip() for sentence in sentences]\n",
        "\n",
        "    # Calculate the word count for each sentence\n",
        "    word_counts = [len(sentence) for sentence in sentences]\n",
        "\n",
        "    # Calculate the average word count\n",
        "    average_word_count = sum(word_counts) / len(word_counts)\n",
        "\n",
        "\n",
        "    print(f\"Word counts: {word_counts}\")\n",
        "    print(f\"Average word count: {average_word_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs2g5AKmSZYj",
        "outputId": "6b252c74-0eb3-4a56-f13d-ca318dcccc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word counts: [2, 3, 4, 3, 2, 4, 5, 2, 4, 2, 3, 3, 2, 5, 2, 4, 2, 3, 4, 5, 3]\n",
            "Average word count: 3.1904761904761907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tree Bank Tokenization"
      ],
      "metadata": {
        "id": "onDgLOA-SzLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class CustomTreebankTokenizer:\n",
        "    def __init__(self):\n",
        "        self.rules = [\n",
        "          (r\"n't\", \" n't\"),\n",
        "            (r\"'re\", \" 're\"),\n",
        "            (r\"'ve\", \" 've\"),\n",
        "            (r\"'ll\", \" 'll\"),\n",
        "            (r\"'d\", \" 'd\"),\n",
        "            (r\"(?<=[a-zA-Z])(?=[,.!?])\", \" \"),\n",
        "            (r\"(\\$\\d+\\.\\d+)\", r\" \\1 \"),\n",
        "            (r\"(\\d+\\.\\d+)\", r\" \\1 \"),\n",
        "            (r\"(\\$[0-9]+)\", r\" \\1 \"),\n",
        "            (r\"([()\\\";:])\", r\" \\1 \"),\n",
        "        ]\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        # Apply each rule sequentially\n",
        "        for pattern, replacement in self.rules:\n",
        "            text = re.sub(pattern, replacement, text)\n",
        "        # Split by whitespace into tokens\n",
        "        tokens = text.split()\n",
        "        return tokens\n",
        "\n",
        "\n",
        "# Example usage\n",
        "text = \"I'm learning NLP. Don't you love it? It's $3.14!\"\n",
        "tokenizer = CustomTreebankTokenizer()\n",
        "tokens = tokenizer.tokenize(text)\n",
        "\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C26bYSHS0fZ",
        "outputId": "7f141e2f-4c32-4655-c28d-9a0a57ad4d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"I'm\", 'learning', 'NLP', '.', 'Do', \"n't\", 'you', 'love', 'it', '?', \"It's\", '$', '3.14', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b1o5W1LiS1-0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}